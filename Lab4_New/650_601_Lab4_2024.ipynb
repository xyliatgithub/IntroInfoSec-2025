{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBdiD49e5Q7L"
      },
      "source": [
        "# **Lab 4: Adversarial Attacks Against Machine Learning Based Spam Filters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPJYb7EA5a24"
      },
      "source": [
        "**Team Number:**\n",
        "\n",
        "**Team Members:**\n",
        "- Member 1:\n",
        "- Member 2:\n",
        "- Member 3:\n",
        "\n",
        "**Contributions:**\n",
        "- Member 1:\n",
        "- Member 2:\n",
        "- Member 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSubQvScyKdQ"
      },
      "source": [
        "## **Introduction**\n",
        "Machine learning-based spam detection models learn from a set of labeled email. One class of vulnerabilities in machine learning models can allow an attack to modify malicious instances to generate adversarial examples. These modified instances may bypass a trained model, e.g., a support vector machine (SVM) classifier used here, without being detected. This is usually done by adding small changes, called perturbations, to the feature vector that the model processes. However, feature extraction methods can make it difficult to translate such numerical perturbation in the feature space, to needed changes to an email consisting of words in the problem space. After all, you can only add or remove a word as whole in the spam scenario of computer security.\n",
        "\n",
        "This lab uses a statistical method to understand how creating adversarial examples purposely modifies a TF-IDF (term frequency-inverse document frequency) feature vector representing an email. A set of \"magic words\" are identified by examining the TF-IDF features to look for those that experience the most significant changes made by a Projected Gradient Descent (PGD) algorithm. These words function in a similar way as in [good word attack](https://www.ceas.cc/papers-2005/125.pdf) previoouly studied. Adding these magic words to a spam email increases the chance of it to pass through the SVM classifier without being filtered out.\n",
        "\n",
        "## **Publications**\n",
        "\n",
        "For more information on this method, you can refer to the following publications:\n",
        "\n",
        "(1) C. Wang, D. Zhang, S. Huang, X. Li, and L. Ding, “Crafting Adversarial Email Content against Machine Learning Based Spam Email Detection,” In Proceedings of the 2021 International Symposium on Advanced Security on Software and Systems (ASSS ’21) with AsiaCCS 2021, Virtual Event, Hong Kong, June 7, 2021. [Download](https://isi.jhu.edu/wp-content/uploads/2021/04/ASSS_Workshop_Paper.pdf)\n",
        "\n",
        "(2) Q. Cheng, A. Xu, X. Li, and L. Ding, “Adversarial Email Generation against Spam Detection Models through Feature Perturbation,” The 2022 IEEE International Conference on Assured Autonomy (ICAA’22), Virtual Event, March 22-23, 2022. [Download](https://isi.jhu.edu/wp-content/uploads/2022/04/Adversarial_Attacks_Against_Machine_Learning_Based_SpamFilters__IEEE.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv-y6Ac6FYWO"
      },
      "source": [
        "## **1. Loading Dataset**\n",
        "The dataset to be used is called Ling-Spam. The Ling-Spam dataset is a collection of 2,893 spam and ham email messages curated from the Linguist List. These messages focus on linguistic interests around job postings, research opportunities, and software discussion. You can download this dataset below coming with the lab assignment.\n",
        "\n",
        "### Acknowledgements\n",
        "The dataset and its information come from the original authors of \"A Memory-Based Approach to Anti-Spam Filtering for Mailing Lists\".\n",
        "\n",
        "**Run the code block below:**\n",
        "\n",
        "choose the message.csv to upload. Wait until it shows 100% before you continue. The below code is for the \"Google Colab\" environment, for another environment (like Jupyter Notebook), you can choose the corresponding upload function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TXkAvUlp4fRP",
        "outputId": "36f9c9c6-1053-43a4-ba3e-b95e2b2e0755"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1re2gZWrle_P"
      },
      "source": [
        "**Run the code block below:**\n",
        "\n",
        "This splits the loaded dataset into three subsets of training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CZvxGJk-rkkc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def data_extraction():\n",
        "\n",
        "  # Change the 'messages.csv' to the filename you uploaded.\n",
        "  df = pd.read_csv('messages.csv')\n",
        "  x = df.message\n",
        "  y = df.label\n",
        "  # We first separate the entire dataset to 80% and 20%.\n",
        "  # Let the 80% of entire dataset becoming the first dataset(which will be split to traning dataset and the validation dataset), and let the 20% of entire dataset becoming the testing dataset.\n",
        "  x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=99, stratify=y)\n",
        "  # Let the 80% of the train_val dataset be the traning dataset, and the 20% of the train_val dataset be the validation dataset.\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=99, stratify=y_train_val)\n",
        "\n",
        "\n",
        "  return x_train, x_val, x_test, y_train, y_val, y_test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2aXVdK7DLuy",
        "outputId": "68f62c08-e395-4e85-d159-98812b1ef571"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = data_extraction()\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFUv7AmsFW8e"
      },
      "source": [
        "In the code block above, we have read the dataset into variables x\n",
        "and y. Variable x contains the email body in a list of words and variable y contains the class labels with 0 being ham and 1 being spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-WXw69wAT6"
      },
      "source": [
        "We divide the entire data set randomly into three different data sets which are training data, validation data, and testing data. After we split the dataset twice: 64% of the entire dataset becomes the traning dataset(Y_train), 16% becomes the validation dataset(X_val), and 20% becomes the testing dataset(X_test).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCGLR9neo8zL"
      },
      "source": [
        "### **Question 1**\n",
        "\n",
        "Why do we need the three data subsets described above? Please explain what is a training dataset, a validation dataset, and a testing dataset. For some additional insights, you can refer to the article at https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7. (However, note that the validation dataset is also used to identify the magical words in this lab, kind of different from its typical use.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJ7iGauJih3"
      },
      "source": [
        "## **2. Preprocessing the Emails**\n",
        "For preparation for use, we remove all the HTML tags, numbers, punctuation marks, and English stop words to keep only useful information. We also convert all the words to lowercase and each paragraph into a single line instead of multiple lines. In the last step of preprocessing, we conduct stemming on all the words.\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfS6VpTaH7Wu",
        "outputId": "a544b40f-a2e5-437d-f228-5bf426fe307c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Remove the hyperlink.\n",
        "def remove_hyperlink(word):\n",
        "\n",
        "    return re.sub(r\"http\\S+\", \" \", word)\n",
        "\n",
        "\n",
        "# Convert the letter to lowercase.\n",
        "def to_lower(word):\n",
        "    result = word.lower()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the numbers.\n",
        "def remove_number(word):\n",
        "    result = re.sub(r'\\d+', ' ', word)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the puncturations.\n",
        "def remove_punctuation(word):\n",
        "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the whitespace.\n",
        "def remove_whitespace(word):\n",
        "    result = word.strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Merge multiple lines into one line.\n",
        "def replace_newline(word):\n",
        "\n",
        "    return word.replace('\\n', ' ')\n",
        "\n",
        "\n",
        "def clean_up_pipeline(sentence):\n",
        "    # Ensure the input is a string\n",
        "    if not isinstance(sentence, str):\n",
        "        sentence = str(sentence)\n",
        "\n",
        "    cleaning_utils = [remove_hyperlink, replace_newline, to_lower, remove_number, remove_punctuation, remove_whitespace]\n",
        "    for o in cleaning_utils:\n",
        "        sentence = o(sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "# Remove the stopwords, for example: a, and, an, above, ..., etc.\n",
        "def remove_stop_words(words):\n",
        "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Reduce a word to its root word.\n",
        "def word_stemmer(words):\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    return [stemmer.stem(o) for o in words]\n",
        "\n",
        "\n",
        "# Remove inflectional endings only and to return the base.\n",
        "def word_lemmatizer(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    return [lemmatizer.lemmatize(o) for o in words]\n",
        "\n",
        "\n",
        "# Clear out the unnecessary information.\n",
        "def clean_token_pipeline(words):\n",
        "    cleaning_utils = [remove_stop_words, word_lemmatizer]\n",
        "\n",
        "    for o in cleaning_utils:\n",
        "        words = o(words)\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "def preprocess(X_train, X_val, X_test):\n",
        "    # Ensure all elements are strings\n",
        "    X_train = [str(x) if not isinstance(x, str) else x for x in X_train]\n",
        "    X_test = [str(x) if not isinstance(x, str) else x for x in X_test]\n",
        "    X_val = [str(x) if not isinstance(x, str) else x for x in X_val]\n",
        "\n",
        "    x_train_clean = [clean_up_pipeline(o) for o in X_train]\n",
        "    x_test_clean = [clean_up_pipeline(o) for o in X_test]\n",
        "    x_val_clean = [clean_up_pipeline(o) for o in X_val]\n",
        "    x_train_tokenize = [word_tokenize(o) for o in x_train_clean]\n",
        "    x_test_tokenize = [word_tokenize(o) for o in x_test_clean]\n",
        "    x_val_tokenize = [word_tokenize(o) for o in x_val_clean]\n",
        "    x_train_clean_token = [clean_token_pipeline(o) for o in x_train_tokenize]\n",
        "    x_test_clean_token = [clean_token_pipeline(o) for o in x_test_tokenize]\n",
        "    x_val_clean_token = [clean_token_pipeline(o) for o in x_val_tokenize]\n",
        "    x_train = [\" \".join(o) for o in x_train_clean_token]\n",
        "    x_test = [\" \".join(o) for o in x_test_clean_token]\n",
        "    x_val = [\" \".join(o) for o in x_val_clean_token]\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoPue9h3Ik--",
        "outputId": "bb80c2ce-579a-4bd8-c484-5ae9081a54bc"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, x_test = preprocess(X_train, X_val, X_test)\n",
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N68YIZqIJmc8"
      },
      "source": [
        "## **3. Feature Extraction**\n",
        "In this step, we convert the words of an email into a numerical feature vector, representing information of that email used for classification. Among many such methods, this lab will use TF-IDF. TF-IDF stands for term frequency-inverse document frequency. It is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining. The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wlpwcsgxJrMK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "def convert_to_feature(raw_tokenize_data):\n",
        "    raw_sentences = [' '.join(o) for o in raw_tokenize_data]\n",
        "\n",
        "    return vectorizer.transform(raw_sentences)\n",
        "\n",
        "\n",
        "def TfidfConvert(x_train, x_test, x_val):\n",
        "    x_train = [o.split(\" \") for o in x_train]\n",
        "    x_test = [o.split(\" \") for o in x_test]\n",
        "    x_val = [o.split(\" \") for o in x_val]\n",
        "    x_train_raw_sentences = [' '.join(o) for o in x_train]\n",
        "    x_val_raw_sentences = [' '.join(o) for o in x_val]\n",
        "    raw_sentences = x_train_raw_sentences + x_val_raw_sentences\n",
        "    vectorizer.fit(raw_sentences)\n",
        "    x_train_features = convert_to_feature(x_train)\n",
        "    x_test_features = convert_to_feature(x_test)\n",
        "    x_val_features = convert_to_feature(x_val)\n",
        "\n",
        "\n",
        "    return x_train_features, x_test_features, x_val_features\n",
        "\n",
        "\n",
        "def feature_extraction(x_train, x_test, x_val):\n",
        "    x_train_features, x_test_features, x_val_features = TfidfConvert(x_train, x_test, x_val)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "    return x_train_features, x_test_features, x_val_features, feature_names, vectorizer, 'NaN'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKUZs88oPQHI",
        "outputId": "adb4bdd5-5206-44b9-ac13-9faf3861988e"
      },
      "outputs": [],
      "source": [
        "x_train_features, x_test_features, x_val_features, feature_names, feature_model, scalar = feature_extraction(x_train, x_test, x_val)\n",
        "print(x_train_features[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MND-TjQRXkpq"
      },
      "source": [
        "### **Question 2**\n",
        "Please research TF-IDF online and provide a concise explanation of how it is done in your own words in one paragraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAbh0HSVrCQd"
      },
      "source": [
        "**Answer 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0RZeCBFLSH9"
      },
      "source": [
        "## **4. Training SVM**\n",
        "In this step, we will train a Support Vector Machine (SVM) model as a spam filter. Then we use the validation dataset to evaluate how it performs.\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAeBdHNfLM7k",
        "outputId": "99c2f58a-467c-4f35-ba46-c54d1110d2c1"
      },
      "outputs": [],
      "source": [
        "!pip install secml\n",
        "from secml.data import CDataset\n",
        "from secml.data.splitter import CDataSplitterKFold\n",
        "from secml.ml.classifiers import CClassifierSVM\n",
        "from secml.ml.peval.metrics import CMetricAccuracy\n",
        "from secml.ml.peval.metrics import CMetricConfusionMatrix\n",
        "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
        "# from Feature_extraction import single_transform\n",
        "import csv\n",
        "from statistics import mean, stdev\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "# We use the training data and validation data set to train the SVM model.\n",
        "def train_SVM(x_train_features, x_val_features, y_train, y_val):\n",
        "    tr_set = CDataset(x_train_features, y_train)\n",
        "    # Train the SVM\n",
        "    print(\"Build SVM\")\n",
        "    xval_splitter = CDataSplitterKFold()\n",
        "    clf_lin = CClassifierSVM()\n",
        "    xval_lin_params = {'C': [1]}\n",
        "    print(\"Find the best params\")\n",
        "    best_lin_params = clf_lin.estimate_parameters(\n",
        "        dataset=tr_set,\n",
        "        parameters=xval_lin_params,\n",
        "        splitter=xval_splitter,\n",
        "        metric='accuracy',\n",
        "        perf_evaluator='xval'\n",
        "    )\n",
        "    print(\"Finish Train\")\n",
        "    print(\"The best training parameters are: \", [\n",
        "          (k, best_lin_params[k]) for k in sorted(best_lin_params)])\n",
        "    print(\"Train SVM\")\n",
        "    clf_lin.fit(tr_set.X, tr_set.Y)\n",
        "\n",
        "    # Test the Classifier\n",
        "    v_set = CDataset(x_val_features, y_val)\n",
        "    y_pred = clf_lin.predict(v_set.X)\n",
        "    metric = CMetricAccuracy()\n",
        "    acc = metric.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    confusion_matrix = CMetricConfusionMatrix()\n",
        "    cm = confusion_matrix.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    print(\"Confusion Matrix: \")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "    return tr_set, v_set, clf_lin\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi5HMdEVQ3a4",
        "outputId": "d06bcbce-c0ba-496e-9572-2e9fba05044e"
      },
      "outputs": [],
      "source": [
        "tr_set, v_set, clf_lin = train_SVM(x_train_features, x_val_features, Y_train, Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL1ZOAYQN12a"
      },
      "source": [
        "### **Question 3**\n",
        "Based on the confusion matrix provided above, calculate the following metrics: `accuracy`, `false-positive rate`, `false-negative rate`, `true-positive rate`, and `true-negative rate`. Please outline the steps you took to calculate each metric and include your results in the text block below. Additionally, provide an explanation of each metric in the context of spam email detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-UG3wUYOaLG"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rKjzZTCO5N2"
      },
      "source": [
        "## **5. Conducting PGD Attacks on Selected Spam Email**\n",
        "Adversarial perturbations are made to input features, i.e., the TF-IDF values corresponding to words. We employ the Projected Gradient Descent (PGD) method to modify the feature values for desirable adversarial examples in the feature domain. PGD algorithm iteratively finds the needed changes with a constraint parameter, *dmax*, which is the Euclidean distance to the original input indicating the allowed extent of perturbation, to achieve the maximum loss in classification. In our approach, we run PGD over a set of randomly selected spam emails form the validation sataset to generate adversarial examples in the feature space. Then we test these modified TF-IDF vectors to see whether they could successfully bypass the detection.\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix7GUWE6yAxQ"
      },
      "source": [
        "**Note:**\n",
        "These are explanations for the terms used in the code:\n",
        "\n",
        "1. `clf_lin` - SVM Classifier:\n",
        "   - Represents a Support Vector Machine (SVM) classifier for email classification.\n",
        "\n",
        "2. `tr_set` - Training Set:\n",
        "   - A dataset used for training the SVM classifier, containing input features and labels.\n",
        "\n",
        "3. `v_set` - Validation Set:\n",
        "   - A dataset used to identify the \"best\" magic words through PGD.\n",
        "\n",
        "4. `Y_val` - Validation Set Labels:\n",
        "   - Contains labels for the validation set, aiding in performance evaluation.\n",
        "\n",
        "5. `feature_names` - Name of the Features:\n",
        "   - Likely holds the names or labels of the dataset's features.\n",
        "\n",
        "6. `nb_attack` - Number of Attacks:\n",
        "   - Determines how many adversarial examples should be generated (the number of spam emails to modify by PGD).\n",
        "\n",
        "7. `dmax` - Maximum Perturbation Distance:\n",
        "   - Represents the maximum allowed change in feature values during adversarial attacks, measured as Euclidean distance.\n",
        "\n",
        "8. `lb` - Lower Bound:\n",
        "   - Sets a lower boundary on feature values, constraining perturbations during attacks.\n",
        "\n",
        "9. `ub` - Upper Bound:\n",
        "   - Defines an upper boundary on feature values, limiting perturbations during attacks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lCvPfWA-P1OG"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(clf_lin, tr_set, v_set, y_val, feature_names, nb_attack, dmax, lb, ub):\n",
        "\n",
        "    class_to_attack = 1\n",
        "    cnt = 0  # the number of success adversaril examples\n",
        "    ori_examples2_x = []\n",
        "    ori_examples2_y = []\n",
        "\n",
        "    for i in range(nb_attack):\n",
        "        # take a point at random being the starting point of the attack\n",
        "        idx_candidates = np.where(y_val == class_to_attack)\n",
        "        # select nb_init_pts points randomly in candidates and make them move\n",
        "        rn = np.random.choice(idx_candidates[0].size, 1)\n",
        "        x0, y0 = v_set[idx_candidates[0][rn[0]], :].X, v_set[idx_candidates[0][rn[0]], :].Y\n",
        "\n",
        "        x0 = x0.astype(float)\n",
        "        y0 = y0.astype(int)\n",
        "        x2 = x0.tondarray()[0]\n",
        "        y2 = y0.tondarray()[0]\n",
        "\n",
        "        ori_examples2_x.append(x2)\n",
        "        ori_examples2_y.append(y2)\n",
        "\n",
        "\n",
        "    # Perform adversarial attacks\n",
        "\n",
        "    noise_type = 'l2'  # Type of perturbation 'l1' or 'l2'\n",
        "\n",
        "    y_target = 0\n",
        "\n",
        "    # dmax = 0.09  # Maximum perturbation\n",
        "\n",
        "    # Bounds of the attack space. Can be set to `None` for unbounded\n",
        "    solver_params = {\n",
        "        'eta': 0.01,\n",
        "        'max_iter': 1000,\n",
        "        'eps': 1e-4}\n",
        "\n",
        "    # set lower bound and upper bound respectively to 0 and 1 since all features are Boolean\n",
        "    pgd_attack = CAttackEvasionPGD(\n",
        "        classifier=clf_lin,\n",
        "        double_init_ds=tr_set,\n",
        "        distance=noise_type,\n",
        "        dmax=dmax,\n",
        "        lb=lb, ub=ub,\n",
        "        solver_params=solver_params,\n",
        "        y_target=y_target\n",
        "    )\n",
        "\n",
        "    ad_examples_x = []\n",
        "    ad_examples_y = []\n",
        "    ad_index = []\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(len(ori_examples2_x)):\n",
        "        x0 = ori_examples2_x[i]\n",
        "        y0 = ori_examples2_y[i]\n",
        "        y_pred_pgd, _, adv_ds_pgd, _ = pgd_attack.run(x0, y0)\n",
        "\n",
        "        if y_pred_pgd.item() == 0:\n",
        "            cnt = cnt + 1\n",
        "            ad_index.append(i)\n",
        "\n",
        "        ad_examples_x.append(adv_ds_pgd.X.tondarray()[0])\n",
        "        ad_examples_y.append(y_pred_pgd.item())\n",
        "\n",
        "        attack_pt = adv_ds_pgd.X.tondarray()[0]\n",
        "\n",
        "    print(\"PGD attack successful rate:\", cnt / nb_attack)\n",
        "\n",
        "    startTime2 = time.time()\n",
        "    ori_examples2_x = np.array(ori_examples2_x)\n",
        "    ori_examples2_y = np.array(ori_examples2_y)\n",
        "    ad_examples_x = np.array(ad_examples_x)\n",
        "    ad_examples_y = np.array(ad_examples_y)\n",
        "\n",
        "    ori_dataframe = pd.DataFrame(ori_examples2_x, columns=feature_names)\n",
        "    ad_dataframe = pd.DataFrame(ad_examples_x, columns=feature_names)\n",
        "\n",
        "    # extract the success and fail examples\n",
        "\n",
        "    ad_dataframe['ad_label'] = ad_examples_y\n",
        "    ad_success = ad_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ori_success = ori_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ad_fail = ad_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "    ori_fail = ori_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "\n",
        "    ad_success_x = ad_success.drop(columns=['ad_label'])\n",
        "    ad_fail_x = ad_fail.drop(columns=['ad_label'])\n",
        "\n",
        "    result = (ad_success_x - ori_success)\n",
        "    ori_dataframe.to_csv('ori_dataframe.csv')\n",
        "    ad_dataframe.to_csv('ad_dataframe.csv')\n",
        "    result.to_csv('result.csv')\n",
        "\n",
        "\n",
        "\n",
        "    return result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, cnt/nb_attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qmM8uxrzrg"
      },
      "source": [
        "**Then run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RYKIvm0QMHD",
        "outputId": "bb09e509-cb76-41ff-dea4-a0fb795bb246"
      },
      "outputs": [],
      "source": [
        "lb = np.ndarray.min(x_train_features.toarray())\n",
        "ub = np.ndarray.max(x_train_features.toarray())\n",
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf2zyWXxnsxx"
      },
      "source": [
        "### **Question 4**\n",
        "Please explain how the success rate is calculated based on the code above using your own words. Then compare this success rate to the original false negative rate of this classifier on the validation set. What do you find?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGPj3veloy7h"
      },
      "source": [
        "**Answer 4:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUx6FBQiCBr"
      },
      "source": [
        "## **6. Identifying Magical Words**\n",
        "Adversarial emails are crafted by adding “magic words” to the original spam emails. The “magic words” are identified by intersecting the unique ham words with the “top words”. Specifically,  the unique ham words only appear in ham emails but not in spam emails.  After the  PGD  attacks on the set of randomly selected spam emails, we examine statistically which features are modified to the largest extent in the effort to bypass detection, to find their corresponding “top words”. (The changes are measured by calculating the variance of TF-IDF differences ver these spam emails before and after the PGD perturbation.) In  our  experiments,  we  use  the  top 100  words,  which  is relatively efficient. This set is relatively small and effective. \n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Mc552xOTSQZn"
      },
      "outputs": [],
      "source": [
        "def magical_word(x_train, x_val, y_train, y_val, x_test, y_test, result, cnt):\n",
        "\n",
        "    # Method 2: calculate feature importance\n",
        "    result_array = np.array(result)\n",
        "    weighted_result = result.multiply(result_array)\n",
        "\n",
        "    average_importance = weighted_result.sum() / cnt\n",
        "    average_importance_df = pd.DataFrame(average_importance, columns=['importance'])\n",
        "    sorted_features = average_importance_df.sort_values(by='importance', ascending=False, inplace=False)\n",
        "\n",
        "    important_features_df = pd.DataFrame(sorted_features.index[:100])\n",
        "    important_features_df.to_csv(\"important_features.csv\")\n",
        "\n",
        "    # Combine train and validation datasets\n",
        "    train_data = pd.DataFrame({'message': x_train, 'label': y_train})\n",
        "    val_data = pd.DataFrame({'message': x_val, 'label': y_val})\n",
        "    combined_data = pd.concat([train_data, val_data])\n",
        "    combined_data.to_csv(\"combined_messages.csv\")\n",
        "\n",
        "    # Separate spam and ham messages\n",
        "    spam_messages = combined_data[combined_data.label == 1]\n",
        "    ham_messages = combined_data[combined_data.label == 0]\n",
        "\n",
        "    # Save test messages\n",
        "    test_data = pd.DataFrame({'message': x_test, 'label': y_test})\n",
        "    test_data.to_csv(\"test_messages.csv\")\n",
        "    spam_test_messages = test_data[test_data.label == 1]\n",
        "\n",
        "    # Tf-idf for spam datasets\n",
        "    tfidf_vectorizer_spam = TfidfVectorizer()\n",
        "    tfidf_vectorizer_spam.fit_transform(spam_messages['message'])\n",
        "    spam_feature_names = tfidf_vectorizer_spam.get_feature_names_out()\n",
        "\n",
        "    # Tf-idf for ham datasets\n",
        "    tfidf_vectorizer_ham = TfidfVectorizer()\n",
        "    tfidf_vectorizer_ham.fit_transform(ham_messages['message'])\n",
        "    ham_feature_names = tfidf_vectorizer_ham.get_feature_names_out()\n",
        "\n",
        "    # find unique ham words\n",
        "    unique_ham_words = list(set(ham_feature_names) - set(spam_feature_names))\n",
        "    unique_ham_words_df = pd.DataFrame(unique_ham_words)\n",
        "    unique_ham_words_df.to_csv(\"unique_ham_words.csv\")\n",
        "\n",
        "    with open(\"important_features.csv\", \"r\") as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        important_features = [row[1] for row in reader]\n",
        "\n",
        "    important_features = important_features[1:]\n",
        "    # in ham & top100\n",
        "\n",
        "    ham_words_in_important_features = list(set(unique_ham_words).intersection(set(important_features)))\n",
        "    ham_words_str = \" \".join(ham_words_in_important_features)\n",
        "\n",
        "    return ham_words_str, spam_messages, ham_messages, spam_test_messages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjldI2rTs_N5"
      },
      "source": [
        "**Run the code block below to list the magic words:**\n",
        "\n",
        "Variable identified_magic_words contains the identified magic words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yC_GNgts8UO",
        "outputId": "7b12ef86-21f6-4be9-cb53-df511ae0d3f3"
      },
      "outputs": [],
      "source": [
        "identified_magic_words, spam, ham, spam_test = magical_word(x_train, x_val, Y_train, Y_val, x_test, Y_test, result, cnt)\n",
        "print(identified_magic_words)\n",
        "print(len(identified_magic_words.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgS8EWh6qwSl"
      },
      "source": [
        "### **Question 5**\n",
        "(1). Based on your understanding after reading the paper using the link below, explain what is a \"good word\" attack?\n",
        "(Reference: https://www.ceas.cc/papers-2005/125.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl1YCa2XyuTM"
      },
      "source": [
        "**Answer 5(1):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulr-4hJpysdz"
      },
      "source": [
        "(2). The use of the good words is similar to our \"magic words\" in this approach.\n",
        "What is the difference in finding \"magic words\" from finding \"good words\"?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owxAMmiYyu5B"
      },
      "source": [
        "**Answer 5(2):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdpkxWJ-RiOz"
      },
      "source": [
        "### **Task 1**\n",
        "In the code block below, try to run pgd_attack with different dmax values.\n",
        "\n",
        "What will happen when you try a higher dmax? Show the relationship by plotting dmax values and the corresponding PGD attack successful rate in a graph. You can do this by changing the code below with different dmax values. Try at least 5 dmax and explain your findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "JgJtZ1gXSNUF",
        "outputId": "f0f8d464-4807-4fd3-b464-7ac1f06cd00a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)\n",
        "\n",
        "# this plot cotains a single dmax vs the successful rate,\n",
        "# you can either write a for loop to try 5 or more dmax, or just manually\n",
        "# modify dmax values and record the results.\n",
        "list_dmax = [dmax]\n",
        "list_successful_rate = [successful_rate]\n",
        "plt.plot(list_dmax, list_successful_rate, 'b-o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr71cHstiQGv"
      },
      "source": [
        "### **Task 2**\n",
        "How many magical words did you get in attacks? List the magical words in the following text block. Find the relationship between the number of magical words and dmax of PGD attack. Plot a graph to show this relationship. Try at least 5 different dmax values. Explain your findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "MUYgM6b2tVQw",
        "outputId": "c8b0ab46-2c9f-4b4c-d7ac-862af683db0f"
      },
      "outputs": [],
      "source": [
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)\n",
        "identified_magic_words, spam, ham, spam_test = magical_word(x_train, x_val, Y_train, Y_val, x_test, Y_test, result, cnt)\n",
        "\n",
        "# this plot cotains a single dmax vs the number of magical words,\n",
        "# you can either write a for loop do to 5 or more dmax, or just manually\n",
        "# record dmax values\n",
        "list_dmax = [dmax]\n",
        "list_len = [len(identified_magic_words.split())]\n",
        "#print (identified_magic_words)\n",
        "#print(list_len)\n",
        "plt.plot(list_dmax, list_len, 'b-o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e3VAwouiQK"
      },
      "source": [
        "## **7. Crafting Adversarial Emails & Attacking SVM**\n",
        "After we find the magical words, we then add them to a spam email to evaluate how effectively the \"magic words\" can bypass the classifier. This is what we called \"crafting adversarial emails\". Then, we feed the new TF-IDF vectors of these crafted emails to the SVM classifier to see if they would be misclassified as ham emails.\n",
        "\n",
        "**Run the code block below:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PxY8tJakw2yv"
      },
      "outputs": [],
      "source": [
        "m2_empty = pd.DataFrame()\n",
        "spam_cnt = 0\n",
        "threads = []\n",
        "m2_empty_l1 = pd.DataFrame()\n",
        "m2_empty_l2 = pd.DataFrame()\n",
        "m2_empty_l3 = pd.DataFrame()\n",
        "m2_empty_l4 = pd.DataFrame()\n",
        "m2_list = [m2_empty_l1, m2_empty_l2, m2_empty_l3, m2_empty_l4]\n",
        "\n",
        "\n",
        "def single_transform(x, method, feature_model, feature_names, scalar, selection_model):\n",
        "\n",
        "  result = feature_model.transform(x)\n",
        "\n",
        "  if selection_model != 'NaN':\n",
        "    result = selection_model.transform(result)\n",
        "\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "class myThread(threading.Thread):\n",
        "\n",
        "    def __init__(self, threadID, name, spam_message, identified_magic_words, method, feature_model, feature_names, scalar, clf_lin, list_index, selection_model):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.threadID = threadID\n",
        "        self.name = name\n",
        "        self.spam_message = spam_message\n",
        "        self.identified_magic_words = identified_magic_words\n",
        "        self.method = method\n",
        "        self.feature_model = feature_model\n",
        "        self.feature_names = feature_names\n",
        "        self.scalar = scalar\n",
        "        self.clf_lin = clf_lin\n",
        "        self.list_index = list_index\n",
        "        self.lock = threading.Lock()\n",
        "        self.selection_model = selection_model\n",
        "\n",
        "    def run(self):\n",
        "        global spam_cnt\n",
        "        print(\"Starting \" + self.name)\n",
        "        spam_cnt_1 = m2_empty_out(self.name, self.spam_message, self.identified_magic_words, self.method,\n",
        "                                  self.feature_model, self.feature_names, self.scalar, self.clf_lin,\n",
        "                                  self.list_index, self.selection_model)\n",
        "        spam_cnt = spam_cnt+spam_cnt_1\n",
        "        time.sleep(0.1)\n",
        "        print(\"Exiting \" + self.name)\n",
        "\n",
        "\n",
        "\n",
        "def m2_empty_out(name, spam_message, identified_magic_words, method, feature_model, feature_names, scalar, clf_lin, list_index, selection_model):\n",
        "    m2_empty_1 = pd.DataFrame()\n",
        "    spam_cnt_1 = 0\n",
        "    global m2_list\n",
        "\n",
        "    for j in spam_message.message:\n",
        "        choose_email = [j + identified_magic_words]\n",
        "        message_14_email = pd.DataFrame(choose_email, columns=[\"message\"])\n",
        "        message_14_tf_idf = single_transform(\n",
        "            message_14_email[\"message\"], method, feature_model, feature_names, scalar, selection_model)\n",
        "        message_14_tf_idf = pd.DataFrame(\n",
        "            message_14_tf_idf.toarray(), columns=feature_names)\n",
        "        message_14_y = [1]\n",
        "        message_14_y = pd.Series(message_14_y)\n",
        "        message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
        "        message_14_pred = clf_lin.predict(message_CData.X)\n",
        "\n",
        "        if message_14_pred == 0:\n",
        "            spam_cnt_1 += 1\n",
        "            m2_empty_1 = pd.concat([m2_empty_1, message_14_tf_idf], ignore_index=True)\n",
        "\n",
        "    m2_list[list_index] = pd.concat([m2_list[list_index], m2_empty_1], ignore_index=True)\n",
        "\n",
        "    return spam_cnt_1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def svm_attack(method, clf_lin, spam, identified_magic_words, feature_model, feature_names, scalar, selection_model):\n",
        "\n",
        "    global m2_empty\n",
        "\n",
        "    spam_messages = np.array_split(spam, 4)\n",
        "\n",
        "    print(\"Start processing message\")\n",
        "\n",
        "    thread1 = myThread(1, \"Thread-1\", spam_messages[0], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 0, selection_model)\n",
        "    thread2 = myThread(2, \"Thread-2\", spam_messages[1], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 1, selection_model)\n",
        "    thread3 = myThread(3, \"Thread-3\", spam_messages[2], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 2, selection_model)\n",
        "    thread4 = myThread(4, \"Thread-4\", spam_messages[3], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 3, selection_model)\n",
        "\n",
        "    threads.append(thread1)\n",
        "    threads.append(thread2)\n",
        "    threads.append(thread3)\n",
        "    threads.append(thread4)\n",
        "\n",
        "    for t in threads:\n",
        "        t.start()\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    m2_empty = pd.concat(m2_list, ignore_index=True)\n",
        "\n",
        "    print(\"Exiting Main Thread\")\n",
        "    print('White box attack on SVM:')\n",
        "    print('Number of samples provided:', len(spam))\n",
        "    print('Number of crafted sample that got misclassified:', spam_cnt)\n",
        "    print('Successful rate:', spam_cnt / len(spam))\n",
        "\n",
        "    return m2_empty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raxGc9-UsT6d"
      },
      "source": [
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo5YVW5zw0Iu",
        "outputId": "8151fba8-10df-4f88-91a1-a7e779b8e107"
      },
      "outputs": [],
      "source": [
        "m2_empty = svm_attack('TFIDF', clf_lin, spam_test, identified_magic_words, feature_model, feature_names, scalar, 'NaN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQOQYRvy4QBG"
      },
      "source": [
        "### **Question 6**\n",
        "Is the success rate shown above higher or lower than the false negative rate of the classifier? Based on this comparison, can we determine if our attack is effective?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX--S66z4SF8"
      },
      "source": [
        "**Answer 6:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znZP1evnzPPd"
      },
      "source": [
        "### **Task 4**\n",
        "Now we will try to craft individual emails by manually changing the text.\n",
        "Follow the steps below for 5 emails:\n",
        "\n",
        "1. Choose an email from the spam dataset.\n",
        "2. Copy the selected email into the code block.\n",
        "3. Add a single magical word obtained from the results of Section 6 to the email, placing it where you see fit.\n",
        "4. Run the code to check if the label is flipped from spam (1) to non-spam (0).\n",
        "5. If the label is flipped, stop. If not, repeat steps 3 and 4 (*add additional magic word*) until the label is flipped or until you've run out of magical words.\n",
        "\n",
        "Tips:\n",
        "1. Here you should note, what exactly is \"Spam Emails\" in this case.\n",
        "2. What should the magical words added to spam_emails be generated from? Is it our validation data or test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XTYSvT12j5y",
        "outputId": "7837b4fb-3e0e-489d-898d-351f2c79d990"
      },
      "outputs": [],
      "source": [
        "# All Spam Emails\n",
        "print(spam_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fqlpi6q3P4-",
        "outputId": "fadb0e9f-2793-41ff-c2d1-5eaac35b2de6"
      },
      "outputs": [],
      "source": [
        "# Choose by varying numbers\n",
        "print(spam_test.message.values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qygv01a_zOGe",
        "outputId": "043d90c4-f0fe-418f-bf09-0e5f7b753a97"
      },
      "outputs": [],
      "source": [
        "choose_email = ['The email content you chose + magical word']\n",
        "message_14_email = pd.DataFrame(choose_email, columns=[\"message\"])\n",
        "message_14_tf_idf = single_transform(message_14_email[\"message\"], 'TFIDF',\n",
        "                    feature_model, feature_names, scalar,\n",
        "                    'NaN')\n",
        "message_14_tf_idf = pd.DataFrame(message_14_tf_idf.toarray(), columns=feature_names)\n",
        "message_14_y = [1]\n",
        "message_14_y = pd.Series(message_14_y)\n",
        "message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
        "message_14_pred = clf_lin.predict(message_CData.X)\n",
        "\n",
        "# if the output is something like CArray([0]), then you flipped the label\n",
        "print('the label after injecting magical word:', message_14_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqgxp_kT4KgP"
      },
      "source": [
        "### **Question 7**\n",
        "How many emails successfully went through (classifiction label flipped to 0) after adding magical words? For each of these emails, how many magical words did you add? (Choose at least 5 emails)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrzWj7MU5Lwu"
      },
      "source": [
        "**Answer 7:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
